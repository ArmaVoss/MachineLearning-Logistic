# Overview

## Goal: Implement a Basic Machine Learning Library
- Modular design with separate gradient calculations, allowing interchangeable loss and activation functions.
- Uses gradient descent to optimize parameters, currently implementing BCE (Binary Cross-Entropy) and a sigmoid activation function.
- Custom Vector and Matrix classes, designed to mimic NumPy syntax.

## Future Plans:
- Implement Singular Value Decomposition (SVD).
- Implement Pseudo-inverse to solve parameters for smaller datasets.
- Implement Linear Regression.
